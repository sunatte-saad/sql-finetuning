{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMvGmeX8TBLK",
        "outputId": "f575204a-0b8b-4a28-9978-8c9a580f64dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in ./venv/lib/python3.10/site-packages (0.111.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in ./venv/lib/python3.10/site-packages (from fastapi) (3.10.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./venv/lib/python3.10/site-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in ./venv/lib/python3.10/site-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in ./venv/lib/python3.10/site-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in ./venv/lib/python3.10/site-packages (from fastapi) (2.2.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in ./venv/lib/python3.10/site-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in ./venv/lib/python3.10/site-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.12.0 in ./venv/lib/python3.10/site-packages (from fastapi) (0.30.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./venv/lib/python3.10/site-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in ./venv/lib/python3.10/site-packages (from fastapi) (5.10.0)\n",
            "Requirement already satisfied: idna>=2.0.0 in ./venv/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in ./venv/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: typer>=0.12.3 in ./venv/lib/python3.10/site-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi) (2024.7.4)\n",
            "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: click>=7.0 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (8.1.7)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (1.0.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (11.0.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.19.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uvicorn in ./venv/lib/python3.10/site-packages (0.30.1)\n",
            "Requirement already satisfied: h11>=0.8 in ./venv/lib/python3.10/site-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in ./venv/lib/python3.10/site-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in ./venv/lib/python3.10/site-packages (from uvicorn) (4.12.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in ./venv/lib/python3.10/site-packages (4.37.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in ./venv/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in ./venv/lib/python3.10/site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in ./venv/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in ./venv/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in ./venv/lib/python3.10/site-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in ./venv/lib/python3.10/site-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in ./venv/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: pydub in ./venv/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in ./venv/lib/python3.10/site-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: gradio-client==1.0.2 in ./venv/lib/python3.10/site-packages (from gradio) (1.0.2)\n",
            "Requirement already satisfied: fastapi in ./venv/lib/python3.10/site-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in ./venv/lib/python3.10/site-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: ffmpy in ./venv/lib/python3.10/site-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in ./venv/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in ./venv/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in ./venv/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in ./venv/lib/python3.10/site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in ./venv/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in ./venv/lib/python3.10/site-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: jinja2<4.0 in ./venv/lib/python3.10/site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in ./venv/lib/python3.10/site-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: matplotlib~=3.0 in ./venv/lib/python3.10/site-packages (from gradio) (3.9.1)\n",
            "Requirement already satisfied: orjson~=3.0 in ./venv/lib/python3.10/site-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in ./venv/lib/python3.10/site-packages (from gradio) (5.3.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in ./venv/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in ./venv/lib/python3.10/site-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from gradio-client==1.0.2->gradio) (2024.5.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in ./venv/lib/python3.10/site-packages (from gradio-client==1.0.2->gradio) (11.0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in ./venv/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.22.0)\n",
            "Requirement already satisfied: toolz in ./venv/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: sniffio in ./venv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: idna in ./venv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: anyio in ./venv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.4.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in ./venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in ./venv/lib/python3.10/site-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./venv/lib/python3.10/site-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in ./venv/lib/python3.10/site-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in ./venv/lib/python3.10/site-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in ./venv/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./venv/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./venv/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in ./venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in ./venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in ./venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./venv/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in ./venv/lib/python3.10/site-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets) (2024.5.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in ./venv/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in ./venv/lib/python3.10/site-packages (0.4.2)\n",
            "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: requests>=2.19.0 in ./venv/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./venv/lib/python3.10/site-packages (from evaluate) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in ./venv/lib/python3.10/site-packages (from evaluate) (0.23.4)\n",
            "Requirement already satisfied: datasets>=2.0.0 in ./venv/lib/python3.10/site-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in ./venv/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: dill in ./venv/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
            "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in ./venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.29.3)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 KB\u001b[0m \u001b[31m412.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.15.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.29.3\n",
            "    Uninstalling accelerate-0.29.3:\n",
            "      Successfully uninstalled accelerate-0.29.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytorch-accelerated 0.1.49 requires accelerate==0.29.3, but you have accelerate 0.32.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.32.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-accelerated in ./venv/lib/python3.10/site-packages (0.1.49)\n",
            "Requirement already satisfied: tqdm~=4.66.0 in ./venv/lib/python3.10/site-packages (from pytorch-accelerated) (4.66.4)\n",
            "Collecting accelerate==0.29.3\n",
            "  Using cached accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (2.3.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (0.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (24.1)\n",
            "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (6.0.1)\n",
            "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate==0.29.3->pytorch-accelerated) (6.0.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.105)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (2024.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (2.3.1)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (3.15.4)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (3.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (10.3.2.106)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (3.1.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (2.20.5)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (1.12.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (12.5.82)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.29.3->pytorch-accelerated) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (2.1.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3->pytorch-accelerated) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3->pytorch-accelerated) (2024.7.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3->pytorch-accelerated) (3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3->pytorch-accelerated) (3.3.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3->pytorch-accelerated) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "Successfully installed accelerate-0.29.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate[torch] in ./venv/lib/python3.10/site-packages (0.29.3)\n",
            "\u001b[33mWARNING: accelerate 0.29.3 does not provide the extra 'torch'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (6.0.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (24.1)\n",
            "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (0.4.3)\n",
            "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate[torch]) (1.26.4)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (3.15.4)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.105)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (1.12.1)\n",
            "Requirement already satisfied: triton==2.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (12.1.105)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate[torch]) (3.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate[torch]) (12.5.82)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate[torch]) (4.66.4)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate[torch]) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate[torch]) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate[torch]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate[torch]) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate[torch]) (2024.7.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate[torch]) (3.7)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#Install dependencies \n",
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install gradio\n",
        "!pip install datasets \n",
        "!pip install evaluate\n",
        "\n",
        "!pip install accelerate -U\n",
        "!pip install pytorch-accelerated\n",
        "!pip install accelerate[torch]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#if you are running this in google colab then you dont need to run this. These libraries come preinstalled with google colab\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t-NO_bPZP6oX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raccoon/Desktop/development/plants/Plant-Disease-Detection/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#necessary imports for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk # install this using pip install datasets, this does not come pre installed with colab\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import accelerate\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTEn5X4RNo0b",
        "outputId": "980e349a-388b-4e9b-a1a9-963d7fd8fd95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking if cudda is available, it might take a long time on the CPU, please change your runtime to GPU on google colab if the output of this cell is false\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MoAwYD-KNqDh"
      },
      "outputs": [],
      "source": [
        "#if you dont have a GPU, then this code with run on CPU.\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_35NrN-KNtDp"
      },
      "outputs": [],
      "source": [
        "#setting up some variables\n",
        "model_name='t5-small'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "original_model = original_model.to(device) #device agnostic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CvovPThMOVIf"
      },
      "outputs": [],
      "source": [
        "# Preparing the dataset for training\n",
        "dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]')\n",
        "dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]')\n",
        "dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]')\n",
        "\n",
        "dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]')\n",
        "dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text'])\n",
        "dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]')\n",
        "dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text'])\n",
        "dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]')\n",
        "dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
        "dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
        "\n",
        "dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
        "dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
        "dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
        "\n",
        "dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
        "                        'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
        "                        'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mhwaOwAOVa_",
        "outputId": "45cf69b5-fbf7-4664-d0e5-4a86b157e891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'SELECT competition FROM table_name_95 WHERE date = \"october 7, 2011\"',\n",
              " 'question': 'What competition was played on October 7, 2011?',\n",
              " 'context': 'CREATE TABLE table_name_95 (competition VARCHAR, date VARCHAR)'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Viewing a single example from the dataset\n",
        "dataset['test'][99]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3dKh10aO6rA",
        "outputId": "4429944f-379d-404f-dd47-7a52665a9fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Tokenized Dataset\n"
          ]
        }
      ],
      "source": [
        "# Maping the dataset and defining our tokenize function\n",
        "def tokenize_function(example):\n",
        "\n",
        "#     print(len(example[\"question\"]))\n",
        "    start_prompt = \"Tables:\\n\"\n",
        "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
        "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
        "\n",
        "    data_zip = zip(example['context'], example['question'])\n",
        "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "#     print(prompt[0])\n",
        "#     print()\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "\n",
        "try:\n",
        "    tokenized_datasets = load_from_disk(\"tokenized_datasets\")\n",
        "    print(\"Loaded Tokenized Dataset\")\n",
        "except:\n",
        "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer'])\n",
        "\n",
        "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
        "    print(\"Tokenized and Saved Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Jia3E1O-Bz",
        "outputId": "322cb53c-c8c0-4e8d-e9e1-c15c1e1d5c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'test', 'validation'])\n",
            "dict_keys(['input_ids', 'labels'])\n",
            "[4398, 7, 10, 205, 4386, 6048, 332, 17098, 819, 41]\n",
            "[3, 23143, 14196, 2847, 17161, 599, 1935, 61, 21680, 819]\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 118695\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 14835\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 14838\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# checking out tokenized version of the dataset\n",
        "print(tokenized_datasets.keys())\n",
        "print(tokenized_datasets['train'][0].keys())\n",
        "print(tokenized_datasets['train'][0]['input_ids'][:10])\n",
        "print(tokenized_datasets['train'][0]['labels'][:10])\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcKg1hGrPBFs",
        "outputId": "04361122-d86c-49da-e3ce-76e0ce88dfd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes of the datasets:\n",
            "Training: (118695, 2)\n",
            "Validation: (14838, 2)\n",
            "Test: (14835, 2)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 118695\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 14835\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 14838\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gNlcSL1sPG9k"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\")\n",
        "    finetuned_model = finetuned_model.to(device)\n",
        "    to_train = False\n",
        "\n",
        "except:\n",
        "    to_train = True\n",
        "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "    finetuned_model = finetuned_model.to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Q-gWgP5FPMTo",
        "outputId": "9ce5e60b-b775-49d3-d1f7-5cdb01f5b892"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='14838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    2/14838 : < :, Epoch 0.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#training cell, this will take a while depending on your hardware, it took me several minutes on a RTX 4090\n",
        "%%time\n",
        "\n",
        "if to_train:\n",
        "    output_dir = f'./sql-training-{str(int(time.time()))}'\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        learning_rate=5e-3,\n",
        "        num_train_epochs=2,\n",
        "        per_device_train_batch_size=16,     # batch size per device during training\n",
        "        per_device_eval_batch_size=16,      # batch size for evaluation\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        evaluation_strategy='steps',        # evaluation strategy to adopt during training\n",
        "        eval_steps=500,                     # number of steps between evaluation\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=finetuned_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets['train'],\n",
        "        eval_dataset=tokenized_datasets['validation'],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    finetuned_model.save_pretrained(\"finetuned_model_2_epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ke5DngIHPPN4"
      },
      "outputs": [],
      "source": [
        "#loading the trained model, if for some reason model is not trained, lets say because of hardware limitations, then we can load the model from the saved version\n",
        "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\")\n",
        "finetuned_model = finetuned_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4nErRDCWPRmr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "Tables:\n",
            "CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)\n",
            "\n",
            "Question:\n",
            "On what Date did the Away team essendon play?\n",
            "\n",
            "Answer:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN ANSWER:\n",
            "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "FINE-TUNED MODEL - ZERO SHOT:\n",
            "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n"
          ]
        }
      ],
      "source": [
        "#inferencing on the test set\n",
        "index = 0\n",
        "# index = len(dataset['test'])-200\n",
        "\n",
        "question = dataset['test'][index]['question']\n",
        "context = dataset['test'][index]['context']\n",
        "answer = dataset['test'][index]['answer']\n",
        "\n",
        "prompt = f\"\"\"Tables:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "output = tokenizer.decode(\n",
        "    finetuned_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
        "print(dash_line)\n",
        "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uJXaBQlNPen6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "# Perform inferences for test dataset. Do 25 only, due to time it takes.\n",
        "\n",
        "questions = dataset['test'][0:25]['question']\n",
        "contexts = dataset['test'][0:25]['context']\n",
        "human_baseline_answers = dataset['test'][0:25]['answer']\n",
        "\n",
        "original_model_answers = []\n",
        "finetuned_model_answers = []\n",
        "\n",
        "for idx, question in enumerate(questions):\n",
        "\n",
        "    prompt = f\"\"\"Tables:\n",
        "{contexts[idx]}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    human_baseline_text_output = human_baseline_answers[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_answers.append(original_model_text_output)\n",
        "\n",
        "    finetuned_model_outputs = finetuned_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=300))\n",
        "    finetuned_model_text_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
        "    finetuned_model_answers.append(finetuned_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_answers, original_model_answers, finetuned_model_answers))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_answers', 'original_model_answers', 'finetuned_model_answers'])\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "r7rNisvAPe14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.03194876200890416, 'rouge2': 0.0054571428571428575, 'rougeL': 0.03174603174603174, 'rougeLsum': 0.03108333984222448}\n",
            "FINE-TUNED MODEL:\n",
            "{'rouge1': 0.6572020416366311, 'rouge2': 0.5613417581194815, 'rougeL': 0.647988094471915, 'rougeLsum': 0.6471310368010181}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_answers,\n",
        "    references=human_baseline_answers[0:len(original_model_answers)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "\n",
        "\n",
        "finetuned_model_results = rouge.compute(\n",
        "    predictions=finetuned_model_answers,\n",
        "    references=human_baseline_answers[0:len(finetuned_model_answers)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "print('FINE-TUNED MODEL:')\n",
        "print(finetuned_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "EITEfTn1PhtV"
      },
      "outputs": [],
      "source": [
        "# Converting the code to a function to be used repeatedly\n",
        "import json\n",
        "\n",
        "def generate_sql_from_text(question, context, tokenizer, finetuned_model, device):\n",
        "    \"\"\"\n",
        "    Generate an SQL query from natural language text using a fine-tuned model.\n",
        "    \n",
        "    Parameters:\n",
        "        question (str): The question in natural language.\n",
        "        context (str): The context or tables information in natural language.\n",
        "        tokenizer (object): The tokenizer to process the input.\n",
        "        finetuned_model (object): The fine-tuned model to generate the SQL query.\n",
        "        device (str): The device to use for computation ('cpu' or 'cuda').\n",
        "        \n",
        "    Returns:\n",
        "        dict: A dictionary containing the input prompt and the model-generated SQL query.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"Tables:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    output = tokenizer.decode(\n",
        "        finetuned_model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=200,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    result = {\n",
        "        \"input_prompt\": prompt,\n",
        "        \"generated_sql_query\": output\n",
        "    }\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_prompt': 'Tables:\\n    Table: Employees (EmployeeID, Name, Department, Salary)\\n\\n    Question:\\n    What is the average salary of employees in the Sales department?\\n\\n    SQL Query:\\n    ', 'generated_sql_query': 'SELECT DISTINCT T1.Name, T1.Name FROM Employee AS T1 JOIN Employee AS T2 ON T1.EmployeeID = T2.EmployeeID GROUP BY T1.Name ORDER BY T1.Name'}\n"
          ]
        }
      ],
      "source": [
        "# function inference for the fine-tuned model\n",
        "question = \"What is the average salary of employees in the Sales department?\"\n",
        "context = \"Table: Employees (EmployeeID, Name, Department, Salary)\"\n",
        "result= generate_sql_from_text(question, context, tokenizer, finetuned_model, device)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for running it the fast api, please run api.py module with its args, \n",
        "# port= 0000 choose any port number to run it on\n",
        "# method= [api,gradio] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
